{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from os import makedirs\n",
    "from argparse import ArgumentParser\n",
    "from argparse import Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams, get_combined_args\n",
    "import numpy as np\n",
    "from scene import Scene, GaussianModel\n",
    "from utils.general_utils import safe_state\n",
    "import open3d as o3d\n",
    "from random import randint\n",
    "from gaussian_renderer import render, network_gui\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Command line Arg\n",
    "sys.argv = [\"train.py\", \"-s\", \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\", \"-r\" ,\"1\"]\n",
    "                        # \"-m\" , \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\output\\\\RGBD_Model\"]\n",
    "\n",
    "parser = ArgumentParser(description='Progressice Gaussian Splatting')\n",
    "model = ModelParams(parser)\n",
    "pipeline = PipelineParams(parser)\n",
    "op = OptimizationParams(parser)\n",
    "\n",
    "# parser.add_argument('--ip', type=str, default=\"127.0.0.1\")\n",
    "# parser.add_argument('--port', type=int, default=6009)\n",
    "# parser.add_argument('--debug_from', type=int, default=-1)\n",
    "# parser.add_argument('--detect_anomaly', action='store_true', default=False)\n",
    "# parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=3000)\n",
    "# parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=3000)\n",
    "parser.add_argument(\"--quiet\", action=\"store_true\")\n",
    "# parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=3000)\n",
    "# parser.add_argument(\"--start_checkpoint\", type=str, default = None)\n",
    "\n",
    "args = parser.parse_args(sys.argv[1:])\n",
    "\n",
    "# Initialize system state (RNG)\n",
    "# safe_state(args.quiet)\n",
    "\n",
    "dataset, iteration, pipeline = model.extract(args), op.extract(args), pipeline.extract(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RGBD Scene\n",
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  2073600\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize Gaussians with Zero Tensor\n",
    "    gaussians = GaussianModel(dataset.sh_degree)\n",
    "    # Load Actual Gaussians, Camera from PCD\n",
    "    scene = Scene(dataset, gaussians, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random Camera\n",
    "viewpoint_stack = None\n",
    "opt = op.extract(args)\n",
    "if not viewpoint_stack:\n",
    "    viewpoint_stack = scene.getTrainCameras().copy()\n",
    "\n",
    "\n",
    "# viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1))\n",
    "# viewpoint_cam = viewpoint_stack[0]\n",
    "# # Render\n",
    "# bg = torch.rand((3), device=\"cuda\")\n",
    "\n",
    "# render_pkg = render(viewpoint_cam, gaussians, pipeline, bg)\n",
    "\n",
    "# image, viewspace_point_tensor, visibility_filter, radii = render_pkg[\"render\"], render_pkg[\"viewspace_points\"], render_pkg[\"visibility_filter\"], render_pkg[\"radii\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_numpy = image.cpu().detach().numpy()\n",
    "\n",
    "# # Transpose the dimensions to [height, width, channels]\n",
    "# image_numpy = np.transpose(image_numpy, (1, 2, 0))\n",
    "\n",
    "# # Display the image using Matplotlib\n",
    "# plt.imshow(image_numpy)\n",
    "# plt.axis('off')  # Turn off axis numbers and ticks\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1080\n",
      "tensor([[-1.0000e+00,  4.3711e-08, -7.5710e-08, -0.0000e+00],\n",
      "        [-1.1384e-09,  8.6603e-01,  5.0000e-01, -0.0000e+00],\n",
      "        [ 7.8368e-08,  5.0000e-01, -8.6603e-01,  0.0000e+00],\n",
      "        [ 5.0000e-01,  1.0000e+00,  2.3000e+00,  1.0000e+00]], device='cuda:0')\n",
      "tensor([[ 0.6174,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.5300,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  1.0001,  1.0000],\n",
      "        [ 0.0000,  0.0000, -0.0100,  0.0000]], device='cuda:0')\n",
      "tensor([[-6.1737e-01, -4.7917e-14,  8.7432e-08,  8.7423e-08],\n",
      "        [ 2.6986e-08,  4.5902e-01,  5.0005e-01,  5.0000e-01],\n",
      "        [-4.6741e-08,  2.6501e-01, -8.6611e-01, -8.6603e-01],\n",
      "        [ 3.0868e-01, -1.0685e+00,  1.4820e+00,  1.4919e+00]], device='cuda:0')\n",
      "tensor([0.5000, 1.0000, 2.3000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "viewpoint_cam = viewpoint_stack[0]\n",
    "print(viewpoint_cam.image_width, viewpoint_cam.image_height)\n",
    "print(viewpoint_cam.world_view_transform.inverse())\n",
    "print(viewpoint_cam.projection_matrix)\n",
    "print(viewpoint_cam.full_proj_transform)\n",
    "print(viewpoint_cam.camera_center)\n",
    "\n",
    "# #save as PLY for verification\n",
    "def saveTensorAsPLY(points,colors, file_name):\n",
    "    point_cloud_np = points.cpu().detach().numpy() \n",
    "    # Create an Open3D point cloud\n",
    "    point_cloud_o3d = o3d.geometry.PointCloud()\n",
    "    point_cloud_o3d.points = o3d.utility.Vector3dVector(point_cloud_np)\n",
    "    point_cloud_o3d.colors = o3d.utility.Vector3dVector(colors.cpu().detach().numpy())\n",
    "    # Save the point cloud as a PLY file\n",
    "    o3d.io.write_point_cloud(file_name, point_cloud_o3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_path = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\ply\"\n",
    "ply_files = os.listdir(ply_path)\n",
    "viewpoint_cam = viewpoint_stack[0]\n",
    "\n",
    "def loadPLY(ply_file):\n",
    "       pcd = o3d.io.read_point_cloud(ply_file)\n",
    "       points = np.asarray(pcd.points)\n",
    "       colors = np.asarray(pcd.colors)\n",
    "       points = torch.from_numpy(points).float().cuda()\n",
    "       colors = torch.from_numpy(colors).float().cuda()\n",
    "       return points, colors\n",
    "\n",
    "def getPixelIndicesfromPLY(points, colors,  viewpoint_cam, sub_pixel_level=1):\n",
    "       # Get Projection Matrix\n",
    "       P = viewpoint_cam.full_proj_transform\n",
    "       \n",
    "       # Project points using projection matrix P in torch cuda and get result in NDC\n",
    "       points_homogeneous = torch.cat((points, torch.ones(points.shape[0], 1, device=points.device)), dim=1)\n",
    "       projected_points_homogeneous = torch.matmul(points_homogeneous, P.t()) # Clip space coordinates\n",
    "\n",
    "       # # Filter points outside clip space\n",
    "       # mask = (projected_points_homogeneous[:, 0] >= -1) & (projected_points_homogeneous[:, 0] < 1) & \\\n",
    "       #        (projected_points_homogeneous[:, 1] >= -1) & (projected_points_homogeneous[:, 1] < 1 ) # & \\\n",
    "              # (projected_points_homogeneous[:, 2] >= -1) & (projected_points_homogeneous[:, 2] < 1) // Removes points closer to camera so not included\n",
    "       # projected_points_homogeneous = projected_points_homogeneous[mask]\n",
    "\n",
    "       # Clip Space / Homogenous to NDC\n",
    "       assert projected_points_homogeneous.shape[1] == 4\n",
    "       # Extract x, y, z, w from the tensor\n",
    "       x, y, z, w = projected_points_homogeneous[:, 0], projected_points_homogeneous[:, 1], projected_points_homogeneous[:, 2], projected_points_homogeneous[:, 3]\n",
    "       x_ndc = x / w\n",
    "       y_ndc = y / w\n",
    "       z_ndc = z / w\n",
    "       projected_points_NDC = torch.stack((x_ndc, y_ndc, z_ndc), dim=1)\n",
    "\n",
    "       # print(projected_points_NDC.shape, projected_points_NDC.min(), projected_points_NDC.max())\n",
    "\n",
    "       # NDC to Image Space [-1,1] to [0,1]\n",
    "       projected_points_IS = (projected_points_NDC + 1) / 2\n",
    "\n",
    "       # Filter points outside image space\n",
    "       mask = (projected_points_IS[:, 0] >= 0) & (projected_points_IS[:, 0] < 1) & \\\n",
    "              (projected_points_IS[:, 1] >= 0) & (projected_points_IS[:, 1] < 1 ) # & \\\n",
    "              # (projected_points_IS[:, 2] >= 0) & (projected_points_IS[:, 2] < 1)\n",
    "       projected_points_IS = projected_points_IS[mask]\n",
    "       points_filtered = points[mask]\n",
    "       colors_filtered = colors[mask]\n",
    "\n",
    "       # print(projected_points_IS.shape, projected_points_IS.min(), projected_points_IS.max())\n",
    "\n",
    "       # Get image width and height\n",
    "       img_width, img_height = viewpoint_cam.image_width, viewpoint_cam.image_height\n",
    "       # Calculate effective pixel width and height based on the sub-pixel variable\n",
    "       effective_pixel_width, effective_pixel_height = img_width // sub_pixel_level, img_height // sub_pixel_level\n",
    "       # Get pixel coordinates\n",
    "       pixel_coordinates = projected_points_IS[:,:2] * torch.tensor([effective_pixel_width, effective_pixel_height], device=points.device).float()\n",
    "       pixel_indices = torch.floor(pixel_coordinates).to(torch.int)\n",
    "\n",
    "       # print(pixel_indices.shape, pixel_indices.min(), pixel_indices.max())\n",
    "       return points_filtered,colors_filtered,pixel_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/60 [00:00<00:30,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized with points from first Frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [00:00<00:16,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new points:  torch.Size([4434, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/60 [00:01<00:14,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new points:  torch.Size([4811, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7/60 [00:01<00:12,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new points:  torch.Size([8180, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 25.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new points:  torch.Size([25732, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new points from PLY\n",
    "sub_pixel_level = 1\n",
    "\n",
    "global_points = None\n",
    "global_colors = None\n",
    "\n",
    "for i in tqdm(range(len(viewpoint_stack))):\n",
    "    viewpoint_cam = viewpoint_stack[i]\n",
    "    # Check if PLY file exists\n",
    "    ply_file_name = viewpoint_cam.colmap_id + \".ply\"\n",
    "    filtered_ply_file_name = viewpoint_cam.colmap_id + \"_filtered.ply\"\n",
    "\n",
    "    # print(ply_file_name)\n",
    "\n",
    "    if ply_file_name not in ply_files:\n",
    "        continue\n",
    "\n",
    "    ply_file_path = os.path.join(ply_path, ply_file_name)\n",
    "    \n",
    "    pcd_points, pcd_colors = loadPLY(ply_file_path)\n",
    "    filtered_points, filtered_colors,  indices = getPixelIndicesfromPLY(pcd_points, pcd_colors, viewpoint_cam)\n",
    "    \n",
    "    # # Load Initial Points\n",
    "    if global_points is None:\n",
    "        print(\"Initialized with points from first Frame\")\n",
    "        global_points = filtered_points\n",
    "        global_colors = filtered_colors\n",
    "    else:\n",
    "        global_filtered_points, global_filtered_colors, global_pixel_indices = getPixelIndicesfromPLY(global_points,global_colors, viewpoint_cam)\n",
    "\n",
    "        # print(indices.shape, global_pixel_indices.shape)\n",
    "        # Find indices of filtered_points that are not present in global_pixel_indices\n",
    "        not_in_global = ~torch.isin(indices, global_pixel_indices).all(dim=1)\n",
    "        \n",
    "        # Get filtered_points that are not present in global_filtered_points\n",
    "        filtered_points_not_in_global = filtered_points[not_in_global]\n",
    "        filtered_colors_not_in_global = filtered_colors[not_in_global]\n",
    "\n",
    "        print(\"Adding new points: \", filtered_points_not_in_global.shape)\n",
    "        \n",
    "        saveTensorAsPLY(filtered_points_not_in_global,filtered_colors_not_in_global, filtered_ply_file_name)\n",
    "        # Append to global points\n",
    "        global_points = torch.cat((global_points, filtered_points_not_in_global), dim=0)\n",
    "        global_colors = torch.cat((global_colors, filtered_colors_not_in_global), dim=0)\n",
    "\n",
    "\n",
    "saveTensorAsPLY(global_points,global_colors, \"Global.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2],[4,5]])\n",
    "b = torch.Tensor([[3,4],[4,5],[0,9]])\n",
    "\n",
    "mask = torch.isin(a,b)\n",
    "\n",
    "mask_all_true = mask.all(dim=1)\n",
    "\n",
    "mask_all_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
