{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from random import randint\n",
    "from scipy.spatial.transform import Rotation\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWorld2View2(R, t, translate=np.array([.0, .0, .0]), scale=1.0):\n",
    "    Rt = np.zeros((4, 4))\n",
    "    Rt[:3, :3] = R.transpose()\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "\n",
    "    C2W = np.linalg.inv(Rt)\n",
    "    cam_center = C2W[:3, 3]\n",
    "    cam_center = (cam_center + translate) * scale\n",
    "    C2W[:3, 3] = cam_center\n",
    "    Rt = np.linalg.inv(C2W)\n",
    "    return np.float32(Rt)\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Camera Parameters:\n",
      "{'resolution': (1920, 1080), 'cx,cy,fx,fy': (959.5, 539.5, 960.0, 960.0), 'k1,k2,k3,p1,p2': (0.0, 0.0, 0.0, 0.0, 0.0), 'vFov': 58.7155, 'hFov': 90.0}\n",
      "\n",
      "Depth Camera Parameters:\n",
      "{'resolution': (512, 424), 'cx,cy,fx,fy': (255.5, 211.5, 256.0, 256.0), 'k1,k2,k3,p1,p2': (0.0, 0.0, 0.0, 0.0, 0.0), 'vFov': 79.2579, 'hFov': 89.9999}\n",
      "\n",
      "Relative Positions of Camera Components:\n",
      "{'RGB sensor': (0.0, 0.0, 0.0), 'RGB light source': (0.0, 0.3, 0.0), 'RGB light source size': (0.4, 0.4), 'Depth sensor': (0.03, 0.0, 0.0), 'Depth light source': (0.06, 0.0, 0.0), 'Depth light source size': (0.02, 0.02)}\n"
     ]
    }
   ],
   "source": [
    "# Camera Intrinsics\n",
    "rgb_camera_params = {}\n",
    "depth_camera_params = {}\n",
    "relative_positions = {}\n",
    "\n",
    "def readRGBDConfig(config_file):\n",
    "    # Define dictionaries to hold camera parameters\n",
    "    # rgb_camera_params = {}\n",
    "    # depth_camera_params = {}\n",
    "    # relative_positions = {}\n",
    "    \n",
    "    with open(config_file, 'r') as file:\n",
    "        data = file.read().split('\\n\\n')\n",
    "    \n",
    "        # Read RGB camera parameters\n",
    "        rgb_data = data[0].split('\\n')\n",
    "        for line in rgb_data[1:4]:\n",
    "            key, value = line.split('=')\n",
    "            if ',' in value:\n",
    "                value = tuple(map(float, value.split(',')))\n",
    "            else:\n",
    "                value = tuple(map(int, value.split('x')))\n",
    "            rgb_camera_params[key] = value\n",
    "\n",
    "        vFOV, hFOV = rgb_data[4].split(',')\n",
    "        key, value = vFOV.split('=')\n",
    "        rgb_camera_params[key] = float(value.strip('°'))\n",
    "        key, value = hFOV.split('=')\n",
    "        rgb_camera_params[key.strip(' ')] = float(value.strip('°'))\n",
    "\n",
    "        # Read Depth camera parameters\n",
    "        depth_data = data[1].split('\\n')\n",
    "        for line in depth_data[1:4]:\n",
    "            key, value = line.split('=')\n",
    "            if ',' in value:\n",
    "                value = tuple(map(float, value.split(',')))\n",
    "            else:\n",
    "                value = tuple(map(int, value.split('x')))\n",
    "            depth_camera_params[key] = value\n",
    "\n",
    "        vFOV, hFOV = depth_data[4].split(',')\n",
    "        key, value = vFOV.split('=')\n",
    "        depth_camera_params[key] = float(value.strip('°'))\n",
    "        key, value = hFOV.split('=')\n",
    "        depth_camera_params[key.strip(' ')] = float(value.strip('°'))\n",
    "\n",
    "    \n",
    "        # Read relative positions of camera components\n",
    "        rel_pos_data = data[2].split('\\n')\n",
    "        for line in rel_pos_data[1:]:\n",
    "            key, value = line.split(': ')\n",
    "            value = tuple(map(float, value.strip('(').strip(')').split(',')))\n",
    "            relative_positions[key] = value\n",
    "\n",
    "        # return rgb_camera_params, depth_camera_params, relative_positions\n",
    "    \n",
    "    # Access the loaded camera parameters\n",
    "    print(\"RGB Camera Parameters:\")\n",
    "    print(rgb_camera_params)\n",
    "    \n",
    "    print(\"\\nDepth Camera Parameters:\")\n",
    "    print(depth_camera_params)\n",
    "    \n",
    "    print(\"\\nRelative Positions of Camera Components:\")\n",
    "    print(relative_positions)\n",
    "\n",
    "conifg = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\config\\\\configuration.txt\"\n",
    "readRGBDConfig(conifg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 5005.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\config\\campose-rgb-0000.txt\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\config\\campose-rgb-0001.txt\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\config\\campose-rgb-0002.txt\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\config\\campose-rgb-0003.txt\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\config\\campose-rgb-0004.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Camera Extrinsics\n",
    "directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\config\"\n",
    "\n",
    "config_files = os.listdir(directory)\n",
    "config_files.sort()\n",
    "\n",
    "extrinsics = {}\n",
    "\n",
    "# config_files[:5]\n",
    "# for file in tqdm(range(len(config_files))):\n",
    "for config_index in tqdm(range(5)):\n",
    "    file = config_files[config_index]\n",
    "    if file.startswith(\"campose-rgb-\"):\n",
    "        frame_id = file.split('-')[2].split('.')[0]\n",
    "        config_file = os.path.join(directory, file)\n",
    "        print(config_file)\n",
    "        \n",
    "        with open(config_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Extracting position\n",
    "            position_str = lines[0].replace('position=', '').split('\\n')[0]\n",
    "            position = np.array([float(i) for i in position_str.strip('()').split(',')])\n",
    "\n",
    "            # Extracting rotation as a quaternion\n",
    "            rotation_str = lines[1].replace('rotation_as_quaternion=', '').split('\\n')[0]\n",
    "            rotation = np.array([float(i) for i in rotation_str.strip('()').split(',')])\n",
    "\n",
    "            # Extracting the 4x4 pose matrix\n",
    "            pose_str = lines[3:]\n",
    "            pose = np.array([[float(i) for i in row.strip('(').split(')')[0].split(',')] for row in pose_str if row != ''])    \n",
    "\n",
    "            # print('Position:', position)\n",
    "            # print('Rotation:',rotation)\n",
    "            # print('Pose:',pose)\n",
    "            extrinsics[frame_id] = pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.00000004 -0.00000008]\n",
      " [-0.          0.866025    0.5       ]\n",
      " [ 0.00000009  0.5        -0.866025  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess RGBD to PLY\n",
    "\n",
    "\n",
    "# Directory where your images are stored\n",
    "directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\rgb\"\n",
    "ply_path = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\ply\"\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Sort the files to process depth and color images together\n",
    "files.sort()\n",
    "\n",
    "# Initialize an empty point cloud\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "start_index = 0\n",
    "ply_files = os.listdir(ply_path)\n",
    "if len(ply_files) > 0:\n",
    "    start_index = int(ply_files[-1].split('.')[0])\n",
    "\n",
    "# Loop through each pair of depth and color images\n",
    "# for i in tqdm(range(start_index, len(files))):\n",
    "for i in tqdm(range(1)):\n",
    "    file = files[i]\n",
    "    # print(file)\n",
    "    if file.startswith(\"gt-rgb-depth-\"):  # Check if the file is a depth image\n",
    "        depth_file = os.path.join(directory, file)\n",
    "        \n",
    "        # Get the corresponding color image\n",
    "        color_file = os.path.join(directory, \"rgb-\" + file[-8:])  # Assuming both files have corresponding indices\n",
    "        \n",
    "        frame_id = file.split('-')[3].split('.')[0]\n",
    "\n",
    "        # Read the depth and color images\n",
    "        depth_image = o3d.io.read_image(depth_file)\n",
    "        color_image = o3d.io.read_image(color_file)\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        depth_array = np.asarray(depth_image)\n",
    "        color_array = np.asarray(color_image)\n",
    "\n",
    "        width = depth_array.shape[1]\n",
    "        height = depth_array.shape[0]\n",
    "        \n",
    "        # Intrinsic parameters of the camera (you may need to adjust these values)\n",
    "        intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "        cx = rgb_camera_params['cx,cy,fx,fy'][0]\n",
    "        cy = rgb_camera_params['cx,cy,fx,fy'][1]\n",
    "        fx = rgb_camera_params['cx,cy,fx,fy'][2] \n",
    "        fy = rgb_camera_params['cx,cy,fx,fy'][3]\n",
    "        intrinsic.set_intrinsics(width=width, height=height, cx=cx, cy=cy, fx=fx, fy=fy)\n",
    "\n",
    "        # print(\"I:\", intrinsic.intrinsic_matrix)\n",
    "        # print(\"P:\", extrinsics[frame_id])\n",
    "\n",
    "        assert frame_id in extrinsics, \"No pose found for frame \" + frame_id\n",
    "\n",
    "        pose = extrinsics[frame_id]\n",
    "        # Extraction of rotation matrix (3x3 sub-matrix)\n",
    "        rotation_matrix = pose[:3, :3]\n",
    "\n",
    "        # Extraction of translation vector (last column)\n",
    "        translation_vector = pose[:3, 3]\n",
    "\n",
    "        # print(pose)\n",
    "        # worldtoview = getWorld2View2(rotation_matrix, translation_vector)\n",
    "        print(rotation_matrix)\n",
    "        # print(translation_vector)\n",
    "        # print(\"W2V:\", worldtoview)\n",
    "\n",
    "        # Create a point cloud from the depth and color information\n",
    "        rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image, depth_image, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic,extrinsic=extrinsics[frame_id])\n",
    "        \n",
    "        pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "        \n",
    "        # Save the point cloud to a file\n",
    "        ply_file_path = os.path.join(ply_path, frame_id + \".ply\")    \n",
    "        \n",
    "        o3d.io.write_point_cloud(ply_file_path, pcd)\n",
    "\n",
    "        # Clear memory\n",
    "        depth_image = None\n",
    "        color_image = None\n",
    "        depth_array = None\n",
    "        color_array = None\n",
    "        pcd = None\n",
    "\n",
    "        # Merge current point cloud with the overall point cloud\n",
    "        # point_cloud += pcd\n",
    "\n",
    "# Visualize the final point cloud\n",
    "# o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86602545  0.5        -0.00000008]\n",
      " [ 0.5        -0.86602607 -0.00000004]\n",
      " [-0.00000009 -0.         -1.00000062]]\n",
      "\n",
      "[[-1.          0.00000004 -0.00000008]\n",
      " [-0.          0.86602549  0.49999985]\n",
      " [ 0.00000009  0.49999985 -0.86602549]]\n"
     ]
    }
   ],
   "source": [
    "rot = qvec2rotmat([1.13133e-08,0.965926,0.258819,-4.2222e-08])\n",
    "rot2 = Rotation.from_quat([1.13133e-08,0.965926,0.258819,-4.2222e-08]).as_matrix()\n",
    "\n",
    "print(rot)\n",
    "print('')\n",
    "print(rot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the final point cloud\n",
    "ply_file_path = os.path.join(ply_path, '0000_P.ply')\n",
    "ply_file_path = os.path.join(ply_path, 'Global.ply')\n",
    "\n",
    "# 4X4 transformation matrix\n",
    "transformation_matrix =  [[1, 0, 0, 0.5],\n",
    "                            [0, 1, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]]\n",
    "\n",
    "\n",
    "ply_files = os.listdir(ply_path)\n",
    "pcd_list = []\n",
    "for file in ply_files[:1]:\n",
    "    if file.endswith(\".ply\"):\n",
    "        pcd_file = os.path.join(ply_path, file)\n",
    "        pcd = o3d.io.read_point_cloud(pcd_file)\n",
    "        pcd.transform(transformation_matrix)\n",
    "        pcd_list.append(pcd)\n",
    "\n",
    "pcd_list.append(o3d.io.read_point_cloud(ply_file_path))\n",
    "o3d.visualization.draw_geometries(pcd_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
