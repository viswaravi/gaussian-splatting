{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from random import randint\n",
    "from scipy.spatial.transform import Rotation\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWorld2View2(R, t, translate=np.array([.0, .0, .0]), scale=1.0):\n",
    "    Rt = np.zeros((4, 4))\n",
    "    Rt[:3, :3] = R.transpose()\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "\n",
    "    C2W = np.linalg.inv(Rt)\n",
    "    cam_center = C2W[:3, 3]\n",
    "    cam_center = (cam_center + translate) * scale\n",
    "    C2W[:3, 3] = cam_center\n",
    "    Rt = np.linalg.inv(C2W)\n",
    "    return np.float32(Rt)\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Camera Parameters:\n",
      "{'resolution': (1920, 1080), 'cx,cy,fx,fy': (959.5, 539.5, 960.0, 960.0), 'k1,k2,k3,p1,p2': (0.0, 0.0, 0.0, 0.0, 0.0), 'vFov': 58.7155, 'hFov': 90.0}\n",
      "\n",
      "Depth Camera Parameters:\n",
      "{'resolution': (512, 424), 'cx,cy,fx,fy': (255.5, 211.5, 256.0, 256.0), 'k1,k2,k3,p1,p2': (0.0, 0.0, 0.0, 0.0, 0.0), 'vFov': 79.2579, 'hFov': 89.9999}\n",
      "\n",
      "Relative Positions of Camera Components:\n",
      "{'RGB sensor': (0.0, 0.0, 0.0), 'RGB light source': (0.0, 0.3, 0.0), 'RGB light source size': (0.4, 0.4), 'Depth sensor': (0.03, 0.0, 0.0), 'Depth light source': (0.06, 0.0, 0.0), 'Depth light source size': (0.02, 0.02)}\n"
     ]
    }
   ],
   "source": [
    "# Camera Intrinsics\n",
    "rgb_camera_params = {}\n",
    "depth_camera_params = {}\n",
    "relative_positions = {}\n",
    "\n",
    "def readRGBDConfig(config_file):\n",
    "    # Define dictionaries to hold camera parameters\n",
    "    # rgb_camera_params = {}\n",
    "    # depth_camera_params = {}\n",
    "    # relative_positions = {}\n",
    "    \n",
    "    with open(config_file, 'r') as file:\n",
    "        data = file.read().split('\\n\\n')\n",
    "    \n",
    "        # Read RGB camera parameters\n",
    "        rgb_data = data[0].split('\\n')\n",
    "        for line in rgb_data[1:4]:\n",
    "            key, value = line.split('=')\n",
    "            if ',' in value:\n",
    "                value = tuple(map(float, value.split(',')))\n",
    "            else:\n",
    "                value = tuple(map(int, value.split('x')))\n",
    "            rgb_camera_params[key] = value\n",
    "\n",
    "        vFOV, hFOV = rgb_data[4].split(',')\n",
    "        key, value = vFOV.split('=')\n",
    "        rgb_camera_params[key] = float(value.strip('°'))\n",
    "        key, value = hFOV.split('=')\n",
    "        rgb_camera_params[key.strip(' ')] = float(value.strip('°'))\n",
    "\n",
    "        # Read Depth camera parameters\n",
    "        depth_data = data[1].split('\\n')\n",
    "        for line in depth_data[1:4]:\n",
    "            key, value = line.split('=')\n",
    "            if ',' in value:\n",
    "                value = tuple(map(float, value.split(',')))\n",
    "            else:\n",
    "                value = tuple(map(int, value.split('x')))\n",
    "            depth_camera_params[key] = value\n",
    "\n",
    "        vFOV, hFOV = depth_data[4].split(',')\n",
    "        key, value = vFOV.split('=')\n",
    "        depth_camera_params[key] = float(value.strip('°'))\n",
    "        key, value = hFOV.split('=')\n",
    "        depth_camera_params[key.strip(' ')] = float(value.strip('°'))\n",
    "\n",
    "    \n",
    "        # Read relative positions of camera components\n",
    "        rel_pos_data = data[2].split('\\n')\n",
    "        for line in rel_pos_data[1:]:\n",
    "            key, value = line.split(': ')\n",
    "            value = tuple(map(float, value.strip('(').strip(')').split(',')))\n",
    "            relative_positions[key] = value\n",
    "\n",
    "        # return rgb_camera_params, depth_camera_params, relative_positions\n",
    "    \n",
    "    # Access the loaded camera parameters\n",
    "    print(\"RGB Camera Parameters:\")\n",
    "    print(rgb_camera_params)\n",
    "    \n",
    "    print(\"\\nDepth Camera Parameters:\")\n",
    "    print(depth_camera_params)\n",
    "    \n",
    "    print(\"\\nRelative Positions of Camera Components:\")\n",
    "    print(relative_positions)\n",
    "\n",
    "config_file = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\config\\\\configuration.txt\"\n",
    "readRGBDConfig(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:00<00:00, 15053.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Camera Extrinsics\n",
    "directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\config\"\n",
    "\n",
    "config_files = os.listdir(directory)\n",
    "config_files.sort()\n",
    "\n",
    "extrinsics = {}\n",
    "\n",
    "# config_files[:5]\n",
    "# for config_index in tqdm(range(5)):\n",
    "for config_index in tqdm(range(len(config_files))):\n",
    "    file = config_files[config_index]\n",
    "    if file.startswith(\"campose-rgb-\"):\n",
    "        frame_id = file.split('-')[2].split('.')[0]\n",
    "        config_file = os.path.join(directory, file)\n",
    "        # print(config_file)\n",
    "        \n",
    "        with open(config_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Extracting position\n",
    "            position_str = lines[0].replace('position=', '').split('\\n')[0]\n",
    "            position = np.array([float(i) for i in position_str.strip('()').split(',')])\n",
    "\n",
    "            # Extracting rotation as a quaternion\n",
    "            rotation_str = lines[1].replace('rotation_as_quaternion=', '').split('\\n')[0]\n",
    "            rotation = np.array([float(i) for i in rotation_str.strip('()').split(',')])\n",
    "\n",
    "            # Extracting the 4x4 pose matrix\n",
    "            pose_str = lines[3:]\n",
    "            pose = np.array([[float(i) for i in row.strip('(').split(')')[0].split(',')] for row in pose_str if row != ''])    \n",
    "\n",
    "            # print('Position:', position)\n",
    "            # print('Rotation:',rotation)\n",
    "            # print('Pose:',pose)\n",
    "            extrinsics[frame_id] = pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 50\n"
     ]
    }
   ],
   "source": [
    "# Directory where your images are stored\n",
    "directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\rgb\"\n",
    "ply_path = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\ply\"\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Sort the files to process depth and color images together\n",
    "files.sort()\n",
    "\n",
    "# Initialize an empty point cloud\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "start_index = 0\n",
    "ply_files = os.listdir(ply_path)\n",
    "if len(ply_files) > 0:\n",
    "    start_index = int(ply_files[-1].split('.')[0])\n",
    "\n",
    "frame_step = 10\n",
    "# Loop through each pair of depth and color images\n",
    "# for i in tqdm(range(1)):\n",
    "\n",
    "depth_files = [file for file in files if file.startswith(\"gt-rgb-depth-\") ]\n",
    "depth_files = depth_files[:50]\n",
    "\n",
    "print(\"Number of files:\", len(depth_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "# Using Open3D to create point clouds\n",
    "if False:\n",
    "# for i in tqdm(range(start_index, len(depth_files),frame_step)):\n",
    "# for i in range(start_index, len(files),frame_step):\n",
    "    depth_file_name = depth_files[i]\n",
    "    # print(file)\n",
    "    # if file.startswith(\"gt-rgb-depth-\"):  # Check if the file is a depth image\n",
    "    depth_file = os.path.join(directory, depth_file_name)\n",
    "    \n",
    "    # Get the corresponding color image\n",
    "    color_file = os.path.join(directory, \"rgb-\" + depth_file_name[-8:])  # Assuming both files have corresponding indices\n",
    "    \n",
    "    frame_id = depth_file_name.split('-')[3].split('.')[0]\n",
    "\n",
    "    # if int(frame_id) not in [146]:\n",
    "    #     continue\n",
    "\n",
    "    # Read the depth and color images\n",
    "    depth_image = o3d.io.read_image(depth_file)\n",
    "    color_image = o3d.io.read_image(color_file)\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_array = np.asarray(depth_image)\n",
    "    color_array = np.asarray(color_image)\n",
    "\n",
    "    width = depth_array.shape[1]\n",
    "    height = depth_array.shape[0]\n",
    "    \n",
    "    # Intrinsic parameters of the camera (you may need to adjust these values)\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = rgb_camera_params['cx,cy,fx,fy'][0]\n",
    "    cy = rgb_camera_params['cx,cy,fx,fy'][1]\n",
    "    fx = rgb_camera_params['cx,cy,fx,fy'][2] \n",
    "    fy = rgb_camera_params['cx,cy,fx,fy'][3]\n",
    "    intrinsic.set_intrinsics(width=width, height=height, cx=cx, cy=cy, fx=fx, fy=fy)\n",
    "\n",
    "    # print(\"I:\", intrinsic.intrinsic_matrix)\n",
    "    # print(\"P:\", extrinsics[frame_id])\n",
    "\n",
    "    assert frame_id in extrinsics, \"No pose found for frame \" + frame_id\n",
    "\n",
    "    pose = np.linalg.inv(extrinsics[frame_id]) \n",
    "\n",
    "    print(\"Frame:\", frame_id)\n",
    "    print(\"Pose:\", pose)\n",
    "\n",
    "    # Extraction of rotation matrix (3x3 sub-matrix)\n",
    "    rotation_matrix = pose[:3, :3]\n",
    "\n",
    "    # Extraction of translation vector (last column)\n",
    "    translation_vector = pose[:3, 3]\n",
    "\n",
    "    # print(pose)\n",
    "    # worldtoview = getWorld2View2(rotation_matrix, translation_vector)\n",
    "    # print(rotation_matrix)\n",
    "    # print(translation_vector)\n",
    "    # print(\"W2V:\", worldtoview)\n",
    "\n",
    "    # Create a point cloud from the depth and color information\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image, depth_image, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic,extrinsic=pose)    \n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "\n",
    "    # Save the point cloud to a file\n",
    "    ply_file_path = os.path.join(ply_path, frame_id + \".ply\")    \n",
    "    # o3d.io.write_point_cloud(ply_file_path, pcd)\n",
    "\n",
    "    # Merge current point cloud with the overall point cloud\n",
    "    point_cloud += pcd\n",
    "\n",
    "    # Clear memory\n",
    "    depth_image = None\n",
    "    color_image = None\n",
    "    depth_array = None\n",
    "    color_array = None\n",
    "    pcd = None\n",
    "\n",
    "\n",
    "# Visualize the final point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: [[960.    0.  959.5]\n",
      " [  0.  960.  539.5]\n",
      " [  0.    0.    1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:11,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: [[960.    0.  959.5]\n",
      " [  0.  960.  539.5]\n",
      " [  0.    0.    1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:05<00:08,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: [[960.    0.  959.5]\n",
      " [  0.  960.  539.5]\n",
      " [  0.    0.    1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:08<00:05,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: [[960.    0.  959.5]\n",
      " [  0.  960.  539.5]\n",
      " [  0.    0.    1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:11<00:02,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: [[960.    0.  959.5]\n",
      " [  0.  960.  539.5]\n",
      " [  0.    0.    1. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "# Using Numpy to create point clouds\n",
    "for i in tqdm(range(start_index, len(depth_files),frame_step)):\n",
    "# for i in range(start_index, len(files),frame_step):\n",
    "# for i in tqdm(range(1)):\n",
    "    depth_file_name = depth_files[i]\n",
    "    depth_file = os.path.join(directory, depth_file_name)\n",
    "    \n",
    "    # Get the corresponding color image\n",
    "    color_file = os.path.join(directory, \"rgb-\" + depth_file_name[-8:])  # Assuming both files have corresponding indices\n",
    "    \n",
    "    frame_id = depth_file_name.split('-')[3].split('.')[0]\n",
    "\n",
    "    # Read the depth and color images\n",
    "    color_image = cv2.imread(color_file)\n",
    "    depth_image = cv2.imread(depth_file, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_array = np.asarray(depth_image)\n",
    "    color_array = np.asarray(color_image)\n",
    "\n",
    "    width = depth_array.shape[1]\n",
    "    height = depth_array.shape[0]\n",
    "\n",
    "    # Intrinsic parameters of the camera (you may need to adjust these values)\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = rgb_camera_params['cx,cy,fx,fy'][0]\n",
    "    cy = rgb_camera_params['cx,cy,fx,fy'][1]\n",
    "    fx = rgb_camera_params['cx,cy,fx,fy'][2] \n",
    "    fy = rgb_camera_params['cx,cy,fx,fy'][3]\n",
    "    intrinsic.set_intrinsics(width=width, height=height, cx=cx, cy=cy, fx=fx, fy=fy)\n",
    "    \n",
    "    # print(\"I:\", intrinsic.intrinsic_matrix)\n",
    "\n",
    "    assert frame_id in extrinsics, \"No pose found for frame \" + frame_id\n",
    "    pose = extrinsics[frame_id]\n",
    "\n",
    "    # print(\"Frame:\", frame_id)\n",
    "    # print(\"Pose:\", pose)\n",
    "\n",
    "    # Convert depth to 3D coordinates in camera coordinates\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    u = u.flatten()\n",
    "    v = v.flatten()\n",
    "\n",
    "    # Convert depth to float32 for accurate calculations\n",
    "    depth_image = depth_image.astype(np.float32)\n",
    "    depth_scale = 1.0 / 1000.0 # The depth scale of the Intel RealSense D435i is 0.001\n",
    "    depth = depth_image.flatten() * depth_scale\n",
    "    X = (u - cx) * depth / fx\n",
    "    Y = (v - cy) * depth / fy\n",
    "    Z = depth\n",
    "\n",
    "    rgb_values = color_array.reshape((-1, 3)) / 255.0\n",
    "    \n",
    "    # Stack the 3D coordinates\n",
    "    points_camera = np.vstack((X, Y, Z, np.ones_like(X)))\n",
    "\n",
    "    if False:\n",
    "        # Extract the transformed X, Y, Z coordinates\n",
    "        X_local = points_camera[0, :]\n",
    "        Y_local = points_camera[1, :]\n",
    "        Z_local = points_camera[2, :]\n",
    "        # Stack the global coordinates\n",
    "        point_cloud_local = np.vstack((X_local, Y_local, Z_local)).T\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud_local)\n",
    "        pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "        # Add color to the point cloud\n",
    "        pcd.colors = o3d.utility.Vector3dVector(rgb_values)\n",
    "        point_cloud += pcd\n",
    "\n",
    "    # Transform to global coordinates\n",
    "    points_global = np.dot(pose, points_camera)\n",
    "\n",
    "    # Extract the transformed X, Y, Z coordinates\n",
    "    X_global = points_global[0, :]\n",
    "    Y_global = points_global[1, :]\n",
    "    Z_global = points_global[2, :]\n",
    "    # Stack the global coordinates\n",
    "    point_cloud_global = np.vstack((X_global, Y_global, Z_global)).T\n",
    "\n",
    "    # Create an Open3D PointCloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    # Set the points in the PointCloud\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud_global)\n",
    "\n",
    "    # Flip the point cloud\n",
    "    # pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "\n",
    "    # Add color to the point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(rgb_values)\n",
    "    \n",
    "    # Save the point cloud to a file\n",
    "    ply_file_path = os.path.join(ply_path, frame_id + \".ply\")    \n",
    "    o3d.io.write_point_cloud(ply_file_path, pcd)\n",
    "\n",
    "    # Merge current point cloud with the overall point cloud\n",
    "    point_cloud += pcd\n",
    "\n",
    "    # Clear memory\n",
    "    depth_image = None\n",
    "    color_image = None\n",
    "    depth_array = None\n",
    "    color_array = None\n",
    "    pcd = None\n",
    "\n",
    "\n",
    "# Create an Open3D mesh representing coordinate axes\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10, origin=[0, 0, 0])\n",
    "\n",
    "# Visualize the final point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud, axes])\n",
    "\n",
    "pcd = None\n",
    "point_cloud = None\n",
    "axes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "# Using Numpy to create point clouds\n",
    "for i in tqdm(range(start_index, len(depth_files),frame_step)):\n",
    "# for i in range(start_index, len(files),frame_step):\n",
    "# for i in tqdm(range(1)):\n",
    "    depth_file_name = depth_files[i]\n",
    "    depth_file = os.path.join(directory, depth_file_name)\n",
    "    \n",
    "    # Get the corresponding color image\n",
    "    color_file = os.path.join(directory, \"rgb-\" + depth_file_name[-8:])  # Assuming both files have corresponding indices\n",
    "    \n",
    "    frame_id = depth_file_name.split('-')[3].split('.')[0]\n",
    "\n",
    "    # Read the depth and color images\n",
    "    color_image = cv2.imread(color_file)\n",
    "    depth_image = cv2.imread(depth_file, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_array = np.asarray(depth_image)\n",
    "    color_array = np.asarray(color_image)\n",
    "\n",
    "    width = depth_array.shape[1]\n",
    "    height = depth_array.shape[0]\n",
    "\n",
    "    # Intrinsic parameters of the camera (you may need to adjust these values)\n",
    "    cx = rgb_camera_params['cx,cy,fx,fy'][0]\n",
    "    cy = rgb_camera_params['cx,cy,fx,fy'][1]\n",
    "    fx = rgb_camera_params['cx,cy,fx,fy'][2] \n",
    "    fy = rgb_camera_params['cx,cy,fx,fy'][3]\n",
    "    \n",
    "    assert frame_id in extrinsics, \"No pose found for frame \" + frame_id\n",
    "    pose = extrinsics[frame_id]\n",
    "\n",
    "    # print(\"Frame:\", frame_id)\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "    K_extended = np.eye(4)\n",
    "    K_extended[:3, :3] = K\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    M = np.dot(K_extended, pose)\n",
    "\n",
    "    pose_inv = np.linalg.inv(pose)\n",
    "\n",
    "    # Convert depth to 3D coordinates in camera coordinates\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    u = u.flatten()\n",
    "    v = v.flatten()\n",
    "\n",
    "    # Convert depth to float32 for accurate calculations\n",
    "    depth_image = depth_image.astype(np.float32)\n",
    "    depth_scale = 1.0 / 1000.0\n",
    "    depth = depth_image.flatten() * depth_scale\n",
    "    \n",
    "    uv_hom =  np.vstack((u, v, np.ones_like(u)))\n",
    "\n",
    "    # print(np.shape(uv_hom), np.shape(K_inv))\n",
    "\n",
    "    points_camera = np.dot(K_inv, uv_hom) * depth\n",
    "\n",
    "    rgb_values = color_array.reshape((-1, 3)) / 255.0\n",
    "    \n",
    "\n",
    "    if False:\n",
    "        # Extract the transformed X, Y, Z coordinates\n",
    "        X_local = points_camera[0, :]\n",
    "        Y_local = points_camera[1, :]\n",
    "        Z_local = points_camera[2, :]\n",
    "        # Stack the global coordinates\n",
    "        point_cloud_local = np.vstack((X_local, Y_local, Z_local)).T\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud_local)\n",
    "        pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "        # Add color to the point cloud\n",
    "        pcd.colors = o3d.utility.Vector3dVector(rgb_values)\n",
    "        point_cloud += pcd\n",
    "    \n",
    "    # print(M.shape)\n",
    "    # print(points_camera.shape)\n",
    "    # Transform to global coordinates\n",
    "    points_camera_homogeneous = np.vstack((points_camera, np.ones(points_camera.shape[1])))\n",
    "    point_3d_homogeneous_global = np.dot(pose_inv, points_camera_homogeneous)\n",
    "    points_global = point_3d_homogeneous_global[:3, :] / point_3d_homogeneous_global[3, :]\n",
    "\n",
    "    # Extract the transformed X, Y, Z coordinates\n",
    "    X_global = points_global[0, :]\n",
    "    Y_global = points_global[1, :]\n",
    "    Z_global = points_global[2, :]\n",
    "    # Stack the global coordinates\n",
    "    point_cloud_global = np.vstack((X_global, Y_global, Z_global)).T\n",
    "\n",
    "    # Create an Open3D PointCloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    # Set the points in the PointCloud\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud_global)\n",
    "\n",
    "    # Flip the point cloud\n",
    "    pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "\n",
    "    # Add color to the point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(rgb_values)\n",
    "    \n",
    "    # Merge current point cloud with the overall point cloud\n",
    "    point_cloud += pcd\n",
    "\n",
    "    # Clear memory\n",
    "    depth_image = None\n",
    "    color_image = None\n",
    "    depth_array = None\n",
    "    color_array = None\n",
    "    pcd = None\n",
    "\n",
    "\n",
    "# Create an Open3D mesh representing coordinate axes\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10, origin=[0, 0, 0])\n",
    "\n",
    "# Visualize the final point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud, axes])\n",
    "\n",
    "pcd = None\n",
    "point_cloud = None\n",
    "axes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot = qvec2rotmat([1.13133e-08,0.965926,0.258819,-4.2222e-08])\n",
    "rot2 = Rotation.from_quat([1.13133e-08,0.965926,0.258819,-4.2222e-08]).as_matrix()\n",
    "\n",
    "print(rot)\n",
    "print('')\n",
    "print(rot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the final point cloud\n",
    "first_ply_file_path = os.path.join(ply_path, '0000.ply')\n",
    "Global_ply_path = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\"\n",
    "ply_file_path = os.path.join(Global_ply_path, 'Global.ply')\n",
    "\n",
    "# 4X4 transformation matrix\n",
    "transformation_matrix =  [[1, 0, 0, 0.5],\n",
    "                            [0, 1, 0, 0],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]]\n",
    "\n",
    "\n",
    "ply_files = os.listdir(ply_path)\n",
    "pcd_list = []\n",
    "# for file in ply_files[:1]:\n",
    "#     if file.endswith(\".ply\"):\n",
    "#         pcd_file = os.path.join(ply_path, file)\n",
    "#         pcd = o3d.io.read_point_cloud(pcd_file)\n",
    "#         pcd.transform(transformation_matrix)\n",
    "#         pcd_list.append(pcd)\n",
    "\n",
    "pcd_list.append(o3d.io.read_point_cloud(ply_file_path))\n",
    "# pcd_list.append(o3d.io.read_point_cloud(first_ply_file_path))\n",
    "\n",
    "# Visualize the final point cloud\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10, origin=[0, 0, 0])\n",
    "o3d.visualization.draw_geometries(pcd_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the filtered point cloud\n",
    "filtered_ply_path = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\ply_filtered\" \n",
    "\n",
    "ply_files = os.listdir(filtered_ply_path)\n",
    "pcd_list = []\n",
    "for file in ply_files:\n",
    "    if file.endswith(\".ply\"):\n",
    "        pcd_file = os.path.join(filtered_ply_path, file)\n",
    "        pcd = o3d.io.read_point_cloud(pcd_file)\n",
    "        pcd.transform(transformation_matrix)\n",
    "        pcd_list.append(pcd)\n",
    "\n",
    "# Visualize the final point cloud\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=10, origin=[0, 0, 0])\n",
    "o3d.visualization.draw_geometries(pcd_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
