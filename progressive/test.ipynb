{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.multiprocessing import Pool, Process, set_start_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([3, 2])\n",
      "tensor([True, True, True])\n"
     ]
    }
   ],
   "source": [
    "u1 = torch.tensor([2, 3, 3])\n",
    "v1 = torch.tensor([6, 4, 6])\n",
    "result1 = torch.stack((u1, v1), dim=1)\n",
    "\n",
    "u2 = torch.tensor([3, 6, 1])\n",
    "v2 = torch.tensor([6, 2, 4])\n",
    "result2 = torch.stack((u2, v2), dim=1)\n",
    "\n",
    "print(result1.shape, result2.shape)\n",
    "# Check if all UV values in result1 are in result2\n",
    "mask = torch.isin(result1, result2).all(dim=1)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[False],\n",
      "        [False],\n",
      "        [False]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 0, 3], \n",
    "                  [4, 0, 2],\n",
    "                  [4, 0, 2]])\n",
    "print(t.shape)\n",
    "mask = torch.all(t == 0, dim=1, keepdim=True)\n",
    "print(mask, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([\n",
    "    [\n",
    "        [1, 0, 3],\n",
    "        [4, 5, 2],\n",
    "        [4, 0, 2],\n",
    "        [4, 0, 2]\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        [1, 0, 3],\n",
    "        [4, 5, 2],\n",
    "        [4, 0, 2],\n",
    "        [4, 0, 2]\n",
    "    ],\n",
    "    [\n",
    "        [1, 0, 3],\n",
    "        [4, 5, 2],\n",
    "        [4, 0, 2],\n",
    "        [4, 0, 2]\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        [1, 0, 3],\n",
    "        [4, 5, 2],\n",
    "        [4, 0, 2],\n",
    "        [4, 0, 2]\n",
    "    ]\n",
    "])\n",
    "print(t.shape)\n",
    "mask = torch.any(t == 0, dim=2, keepdim=True)\n",
    "# print(mask, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 2],\n",
       "        [4, 0, 2],\n",
       "        [4, 0, 2],\n",
       "        [4, 0, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv = [[0,1], [1,2], [2,3], [3,3]]\n",
    "uv = torch.tensor(uv)\n",
    "\n",
    "print(uv.shape)\n",
    "\n",
    "rgb = [[0,1,2], [1,2,3], [2,3,4], [3,4,5]]\n",
    "rgb = torch.tensor(rgb)\n",
    "\n",
    "t[uv[:,0], uv[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # showRasterizedImageComp(current_raster, global_raster)\n",
    "        # cv2.imwrite(\"Current.png\", (current_raster* 255).astype(np.uint8))\n",
    "        # cv2.imwrite(\"Global.png\", (global_raster* 255).astype(np.uint8))\n",
    "        \n",
    "        # # print(indices.shape, global_pixel_indices.shape)\n",
    "        # # Find indices of filtered_points that are not present in global_pixel_indices\n",
    "        # # not_in_global = torch.isin(indices, global_pixel_indices).all(dim=1)\n",
    "        # not_in_global = ~customIsIn2Batched(indices, global_pixel_indices)\n",
    "        \n",
    "        # # Get filtered_points that are not present in global_filtered_points\n",
    "        # filtered_points_not_in_global = filtered_points[not_in_global]\n",
    "        # filtered_colors_not_in_global = filtered_colors[not_in_global]\n",
    "        # indices_not_in_global = indices[not_in_global]\n",
    "\n",
    "        # showFilterMaskImage(indices_not_in_global)\n",
    "        # raster = showRasterizedImage(indices_not_in_global[:,0], indices_not_in_global[:,1], filtered_colors_not_in_global)\n",
    "        # plt.imshow(raster)\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        # print(\"Adding new points: \", filtered_points_not_in_global.shape)\n",
    "        \n",
    "        # saveTensorAsPLY(filtered_points_not_in_global,filtered_colors_not_in_global, filtered_ply_file_name)\n",
    "        # Append to global points\n",
    "        # global_points = torch.cat((global_points, filtered_points_not_in_global), dim=0)\n",
    "        # global_colors = torch.cat((global_colors, filtered_colors_not_in_global), dim=0)\n",
    "\n",
    "# saveTensorAsPLY(global_points,global_colors, \"Global.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customIsIn(result1, result2):\n",
    "    mask = []\n",
    "    for i in range(result1.shape[0]):\n",
    "        for UV in result2:\n",
    "            if torch.equal(UV, result1[i]):\n",
    "                mask.append(True)\n",
    "                break\n",
    "        if len(mask) != i+1:\n",
    "            mask.append(False)\n",
    "    return torch.tensor(mask, device=result1.device)\n",
    "\n",
    "mask1 = customIsIn(result1, result2)\n",
    "print(mask1)\n",
    "\n",
    "\n",
    "def customIsIn2(result1, result2):\n",
    "    result1_expanded = result1.unsqueeze(1)\n",
    "    result2_expanded = result2.unsqueeze(0)\n",
    "    is_combination_in_result2 = torch.all(result1_expanded == result2_expanded, dim=2)\n",
    "    # print(is_combination_in_result2)\n",
    "    return torch.any(is_combination_in_result2, dim=1)\n",
    "\n",
    "def customIsIn2Batched(result1, result2):\n",
    "    # Set a batch size based on your available GPU memory\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Number of batches\n",
    "    num_batches = result1.shape[0] // batch_size + 1\n",
    "\n",
    "    # Initialize an empty tensor to store the comparison results\n",
    "    is_combination_in_result2 = torch.empty(result1.shape[0], result2.shape[0], dtype=torch.bool)\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, result1.shape[0])\n",
    "\n",
    "        # Extract a batch from result1\n",
    "        result1_batch = result1[start_idx:end_idx].unsqueeze(1)\n",
    "\n",
    "        # Expand dimensions for broadcasting\n",
    "        result1_batch_expanded = result1_batch.unsqueeze(2)\n",
    "        result2_expanded = result2.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Element-wise comparison for the batch\n",
    "        is_combination_in_result2[start_idx:end_idx] = torch.all(result1_batch_expanded == result2_expanded, dim=-1)\n",
    "\n",
    "    return torch.any(is_combination_in_result2, dim=2)\n",
    "\n",
    "mask2 = customIsIn2(result1, result2)\n",
    "print(mask2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
