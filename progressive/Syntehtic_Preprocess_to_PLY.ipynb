{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from random import randint\n",
    "from scipy.spatial.transform import Rotation\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWorld2View2(R, t, translate=np.array([.0, .0, .0]), scale=1.0):\n",
    "    Rt = np.zeros((4, 4))\n",
    "    Rt[:3, :3] = R.transpose()\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "\n",
    "    C2W = np.linalg.inv(Rt)\n",
    "    cam_center = C2W[:3, 3]\n",
    "    cam_center = (cam_center + translate) * scale\n",
    "    C2W[:3, 3] = cam_center\n",
    "    Rt = np.linalg.inv(C2W)\n",
    "    return np.float32(Rt)\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'resolution': (1920, 1080),\n",
       "  'cx,cy,fx,fy': (959.5, 539.5, 960.0, 960.0),\n",
       "  'k1,k2,k3,p1,p2': (0.0, 0.0, 0.0, 0.0, 0.0),\n",
       "  'vFov': 58.7155,\n",
       "  'hFov': 90.0},\n",
       " {'resolution': (512, 424),\n",
       "  'cx,cy,fx,fy': (255.5, 211.5, 256.0, 256.0),\n",
       "  'k1,k2,k3,p1,p2': (0.0, 0.0, 0.0, 0.0, 0.0),\n",
       "  'vFov': 79.2579,\n",
       "  'hFov': 89.9999},\n",
       " {'RGB sensor': (0.0, 0.0, 0.0),\n",
       "  'RGB light source': (0.0, 0.3, 0.0),\n",
       "  'RGB light source size': (0.4, 0.4),\n",
       "  'Depth sensor': (0.03, 0.0, 0.0),\n",
       "  'Depth light source': (0.06, 0.0, 0.0),\n",
       "  'Depth light source size': (0.02, 0.02)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Camera Intrinsics\n",
    "rgb_camera_params = {}\n",
    "depth_camera_params = {}\n",
    "relative_positions = {}\n",
    "\n",
    "def readRGBDConfig(config_file):\n",
    "    # Define dictionaries to hold camera parameters\n",
    "    # rgb_camera_params = {}\n",
    "    # depth_camera_params = {}\n",
    "    # relative_positions = {}\n",
    "    \n",
    "    with open(config_file, 'r') as file:\n",
    "        data = file.read().split('\\n\\n')\n",
    "    \n",
    "        # Read RGB camera parameters\n",
    "        rgb_data = data[0].split('\\n')\n",
    "        for line in rgb_data[1:4]:\n",
    "            key, value = line.split('=')\n",
    "            if ',' in value:\n",
    "                value = tuple(map(float, value.split(',')))\n",
    "            else:\n",
    "                value = tuple(map(int, value.split('x')))\n",
    "            rgb_camera_params[key] = value\n",
    "\n",
    "        vFOV, hFOV = rgb_data[4].split(',')\n",
    "        key, value = vFOV.split('=')\n",
    "        rgb_camera_params[key] = float(value.strip('°'))\n",
    "        key, value = hFOV.split('=')\n",
    "        rgb_camera_params[key.strip(' ')] = float(value.strip('°'))\n",
    "\n",
    "        # Read Depth camera parameters\n",
    "        depth_data = data[1].split('\\n')\n",
    "        for line in depth_data[1:4]:\n",
    "            key, value = line.split('=')\n",
    "            if ',' in value:\n",
    "                value = tuple(map(float, value.split(',')))\n",
    "            else:\n",
    "                value = tuple(map(int, value.split('x')))\n",
    "            depth_camera_params[key] = value\n",
    "\n",
    "        vFOV, hFOV = depth_data[4].split(',')\n",
    "        key, value = vFOV.split('=')\n",
    "        depth_camera_params[key] = float(value.strip('°'))\n",
    "        key, value = hFOV.split('=')\n",
    "        depth_camera_params[key.strip(' ')] = float(value.strip('°'))\n",
    "\n",
    "    \n",
    "        # Read relative positions of camera components\n",
    "        rel_pos_data = data[2].split('\\n')\n",
    "        for line in rel_pos_data[1:]:\n",
    "            key, value = line.split(': ')\n",
    "            value = tuple(map(float, value.strip('(').strip(')').split(',')))\n",
    "            relative_positions[key] = value\n",
    "\n",
    "        return rgb_camera_params, depth_camera_params, relative_positions\n",
    "    \n",
    "    # Access the loaded camera parameters\n",
    "    print(\"RGB Camera Parameters:\")\n",
    "    print(rgb_camera_params)\n",
    "    \n",
    "    print(\"\\nDepth Camera Parameters:\")\n",
    "    print(depth_camera_params)\n",
    "    \n",
    "    # print(\"\\nRelative Positions of Camera Components:\")\n",
    "    # print(relative_positions)\n",
    "\n",
    "config_file = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV1\\\\config\\\\configuration.txt\"\n",
    "# config_file = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV2\\\\configuration.txt\"\n",
    "readRGBDConfig(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Camera Intrinsic Matrix:\n",
      "[[960.    0.  959.5]\n",
      " [  0.  960.  539.5]\n",
      " [  0.    0.    1. ]]\n",
      "[0. 0. 0. 0. 0.]\n",
      "TOF Camera Intrinsic Matrix:\n",
      "[[256.    0.  255.5]\n",
      " [  0.  256.  211.5]\n",
      " [  0.    0.    1. ]]\n",
      "[0. 0. 0. 0. 0.]\n",
      "Extrinsic Matrix: [[1.   0.   0.   0.03]\n",
      " [0.   1.   0.   0.  ]\n",
      " [0.   0.   1.   0.  ]\n",
      " [0.   0.   0.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "cx = rgb_camera_params['cx,cy,fx,fy'][0]\n",
    "cy = rgb_camera_params['cx,cy,fx,fy'][1]\n",
    "fx = rgb_camera_params['cx,cy,fx,fy'][2] \n",
    "fy = rgb_camera_params['cx,cy,fx,fy'][3]\n",
    "\n",
    "k1 = rgb_camera_params['k1,k2,k3,p1,p2'][0]\n",
    "k2 = rgb_camera_params['k1,k2,k3,p1,p2'][1]\n",
    "k3 = rgb_camera_params['k1,k2,k3,p1,p2'][2]\n",
    "p1 = rgb_camera_params['k1,k2,k3,p1,p2'][3] \n",
    "p2 = rgb_camera_params['k1,k2,k3,p1,p2'][4]\n",
    "\n",
    "\n",
    "# RGB Camera Intrinsic Matrix\n",
    "K_rgb = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "D_rgb = np.array([k1, k2, p1, p2, k3])\n",
    "\n",
    "cx_tof = depth_camera_params['cx,cy,fx,fy'][0]\n",
    "cy_tof = depth_camera_params['cx,cy,fx,fy'][1]\n",
    "fx_tof = depth_camera_params['cx,cy,fx,fy'][2] \n",
    "fy_tof = depth_camera_params['cx,cy,fx,fy'][3]\n",
    "\n",
    "k1_tof = rgb_camera_params['k1,k2,k3,p1,p2'][0]\n",
    "k2_tof = rgb_camera_params['k1,k2,k3,p1,p2'][1]\n",
    "k3_tof = rgb_camera_params['k1,k2,k3,p1,p2'][2]\n",
    "p1_tof = rgb_camera_params['k1,k2,k3,p1,p2'][3] \n",
    "p2_tof = rgb_camera_params['k1,k2,k3,p1,p2'][4]\n",
    "\n",
    "\n",
    "# TOF Camera Intrinsic Matrix\n",
    "K_tof = np.array([[fx_tof, 0, cx_tof],\n",
    "                  [0, fy_tof, cy_tof],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "D_tof = np.array([k1_tof, k2_tof, p1_tof, p2_tof, k3_tof])\n",
    "\n",
    "print(\"RGB Camera Intrinsic Matrix:\")\n",
    "print(K_rgb)\n",
    "print(D_rgb)\n",
    "print(\"TOF Camera Intrinsic Matrix:\")\n",
    "print(K_tof)\n",
    "print(D_tof)\n",
    "\n",
    "# Relative translation\n",
    "translation = np.array([0.03,0,0])  # Replace with your actual translation values\n",
    "\n",
    "# Relative rotation\n",
    "rotation = np.eye(3)  # Replace with your actual rotation matrix\n",
    "\n",
    "# Compose transformation matrix\n",
    "extrinsic_matrix = np.column_stack((rotation, translation))\n",
    "tof_extrinsic_matrix = np.row_stack((extrinsic_matrix, [0, 0, 0, 1]))\n",
    "\n",
    "print(\"Extrinsic Matrix:\", tof_extrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:00<00:00, 7771.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Camera Extrinsics\n",
    "pose_directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV1\\\\config\"\n",
    "# pose_directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV2\\\\trajectory\"\n",
    "\n",
    "\n",
    "config_files = os.listdir(pose_directory)\n",
    "config_files.sort()\n",
    "\n",
    "extrinsics = {}\n",
    "\n",
    "# config_files[:5]\n",
    "# for config_index in tqdm(range(5)):\n",
    "for config_index in tqdm(range(len(config_files))):\n",
    "    file = config_files[config_index]\n",
    "    if file.startswith(\"campose-rgb-\"):\n",
    "        frame_id = file.split('-')[2].split('.')[0]\n",
    "        config_file = os.path.join(pose_directory, file)\n",
    "        # print(config_file)\n",
    "        \n",
    "        with open(config_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Extracting position\n",
    "            position_str = lines[0].replace('position=', '').split('\\n')[0]\n",
    "            position = np.array([float(i) for i in position_str.strip('()').split(',')])\n",
    "\n",
    "            # Extracting rotation as a quaternion\n",
    "            rotation_str = lines[1].replace('rotation_as_quaternion=', '').split('\\n')[0]\n",
    "            rotation = np.array([float(i) for i in rotation_str.strip('()').split(',')])\n",
    "\n",
    "            # Extracting the 4x4 pose matrix\n",
    "            pose_str = lines[3:]\n",
    "            pose = np.array([[float(i) for i in row.strip('(').split(')')[0].split(',')] for row in pose_str if row != ''])    \n",
    "\n",
    "            # print('Position:', position)\n",
    "            # print('Rotation:',rotation)\n",
    "            # print('Pose:',pose)\n",
    "            extrinsics[frame_id] = pose\n",
    "\n",
    "print(\"Number of frames:\", len(extrinsics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 50\n",
      "Start index: 0\n"
     ]
    }
   ],
   "source": [
    "# Directory where your images are stored\n",
    "# rgb_directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV1\\\\rgb\"\n",
    "# depth_directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV1\\\\rgb\"\n",
    "\n",
    "depth_directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV2\\\\gt_depth\"\n",
    "rgb_directory = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\SyntheticV2\\\\color\"\n",
    "ply_path = \"G:\\\\Universitat Siegen\\\\SA\\\\P-GPU\\\\Code\\\\gaussian-splatting\\\\data\\\\RGBD_Data\\\\ply\"\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(depth_directory)\n",
    "\n",
    "# Sort the files to process depth and color images together\n",
    "files.sort()\n",
    "\n",
    "# Initialize an empty point cloud\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "start_index = 0\n",
    "ply_files = os.listdir(ply_path)\n",
    "if len(ply_files) > 0:\n",
    "    start_index = int(ply_files[-1].split('.')[0])\n",
    "\n",
    "frame_step = 10\n",
    "# Loop through each pair of depth and color images\n",
    "# for i in tqdm(range(1)):\n",
    "\n",
    "depth_files = [file for file in files if file.startswith(\"gt-rgb-depth-\") ]\n",
    "depth_files = depth_files[:50]\n",
    "\n",
    "print(\"Number of files:\", len(depth_files))\n",
    "print(\"Start index:\", start_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "# Using Open3D to create point clouds\n",
    "if False:\n",
    "# for i in tqdm(range(start_index, len(depth_files),frame_step)):\n",
    "# for i in range(start_index, 10 ,frame_step):\n",
    "    depth_file_name = depth_files[i]\n",
    "    # print(file)\n",
    "    # if file.startswith(\"gt-rgb-depth-\"):  # Check if the file is a depth image\n",
    "    depth_file = os.path.join(directory, depth_file_name)\n",
    "    \n",
    "    # Get the corresponding color image\n",
    "    color_file = os.path.join(directory, \"rgb-\" + depth_file_name[-8:])  # Assuming both files have corresponding indices\n",
    "    \n",
    "    frame_id = depth_file_name.split('-')[3].split('.')[0]\n",
    "\n",
    "    # Read the depth and color images\n",
    "    depth_image = cv2.imread(depth_file, cv2.IMREAD_UNCHANGED)\n",
    "    depth_image = cv2.resize(depth_image, (512, 424), interpolation=cv2.INTER_NEAREST)\n",
    "    color_image = cv2.imread(color_file, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_array = np.asarray(depth_image)\n",
    "    color_array = np.asarray(color_image)\n",
    "\n",
    "    width = depth_array.shape[1]\n",
    "    height = depth_array.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Intrinsic parameters of the camera (you may need to adjust these values)\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = depth_camera_params['cx,cy,fx,fy'][0]\n",
    "    cy = depth_camera_params['cx,cy,fx,fy'][1]\n",
    "    fx = depth_camera_params['cx,cy,fx,fy'][2] \n",
    "    fy = depth_camera_params['cx,cy,fx,fy'][3]\n",
    "    intrinsic.set_intrinsics(width=width, height=height, cx=cx, cy=cy, fx=fx, fy=fy)\n",
    "\n",
    "    # print(\"I:\", intrinsic.intrinsic_matrix)\n",
    "    # print(\"P:\", extrinsics[frame_id])\n",
    "\n",
    "    assert frame_id in extrinsics, \"No pose found for frame \" + frame_id\n",
    "\n",
    "    pose = extrinsics[frame_id]\n",
    "\n",
    "    # print(\"Frame:\", frame_id)\n",
    "    # print(\"Pose:\", pose)\n",
    "\n",
    "    # Extraction of rotation matrix (3x3 sub-matrix)\n",
    "    rotation_matrix = pose[:3, :3]\n",
    "\n",
    "    # Extraction of translation vector (last column)\n",
    "    translation_vector = pose[:3, 3]\n",
    "\n",
    "    # print(pose)\n",
    "    # worldtoview = getWorld2View2(rotation_matrix, translation_vector)\n",
    "    # print(rotation_matrix)\n",
    "    # print(translation_vector)\n",
    "    # print(\"W2V:\", worldtoview)\n",
    "\n",
    "    # Create a point cloud from the depth and color information\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(color_image, depth_image, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic,extrinsic=pose)    \n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "\n",
    "    # Save the point cloud to a file\n",
    "    ply_file_path = os.path.join(ply_path, frame_id + \".ply\")    \n",
    "    # o3d.io.write_point_cloud(ply_file_path, pcd)\n",
    "\n",
    "    # Merge current point cloud with the overall point cloud\n",
    "    point_cloud += pcd\n",
    "\n",
    "    # Clear memory\n",
    "    depth_image = None\n",
    "    color_image = None\n",
    "    depth_array = None\n",
    "    color_array = None\n",
    "    pcd = None\n",
    "\n",
    "\n",
    "# Visualize the final point cloud\n",
    "# o3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UVD Function based Implementation\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "SAMPLE_RATIO = 0.05\n",
    "\n",
    "def convert_from_uvd(u, v, d, intr, pose):\n",
    "    if d == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    fx = intr[0, 0]\n",
    "    fy = intr[1, 1]\n",
    "    cx = intr[0, 2]\n",
    "    cy = intr[1, 2]\n",
    "    depth_scale = 1000\n",
    "    \n",
    "    z = d / depth_scale\n",
    "    x = (u - cx) * z / fx\n",
    "    y = (v - cy) * z / fy\n",
    "    \n",
    "    world = (pose @ np.array([x, y, z, 1]))\n",
    "    return world[:3] / world[3]\n",
    "\n",
    "# Using Numpy to create point clouds\n",
    "# for i in tqdm(range(start_index, len(depth_files),frame_step)):\n",
    "for i in range(0, 20,10):\n",
    "    depth_file_name = depth_files[i]\n",
    "    depth_file = os.path.join(depth_directory, depth_file_name)\n",
    "    \n",
    "    # Get the corresponding color image\n",
    "    color_file = os.path.join(rgb_directory, \"rgb-\" + depth_file_name[-8:])  # Assuming both files have corresponding indices\n",
    "    \n",
    "    frame_id = depth_file_name.split('-')[3].split('.')[0]\n",
    "\n",
    "    # Read the depth and color images\n",
    "    depth_image = cv2.imread(depth_file, cv2.IMREAD_UNCHANGED)\n",
    "    depth_image = cv2.resize(depth_image, (512, 424), interpolation=cv2.INTER_NEAREST)\n",
    "    color_image = cv2.imread(color_file, cv2.IMREAD_UNCHANGED)\n",
    "    color_image = cv2.resize(color_image, (512, 424), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_array = np.asarray(depth_image)\n",
    "    color_array = np.asarray(color_image)\n",
    "    \n",
    "    width = depth_array.shape[1]\n",
    "    height = depth_array.shape[0]\n",
    "\n",
    "    assert frame_id in extrinsics, \"No pose found for frame \" + str(frame_id)\n",
    "    intrinsic = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cx = depth_camera_params['cx,cy,fx,fy'][0]\n",
    "    cy = depth_camera_params['cx,cy,fx,fy'][1]\n",
    "    fx = depth_camera_params['cx,cy,fx,fy'][2] \n",
    "    fy = depth_camera_params['cx,cy,fx,fy'][3]\n",
    "    intrinsic.set_intrinsics(width=width, height=height, cx=cx, cy=cy, fx=fx, fy=fy)\n",
    "    intrinsic_matrix = np.array(intrinsic.intrinsic_matrix)\n",
    "    # print(\"I:\", intrinsic_matrix)\n",
    "\n",
    "    pose = extrinsics[frame_id]\n",
    "\n",
    "    # print(\"Frame:\", frame_id)\n",
    "    # print(\"Pose:\", pose)\n",
    "\n",
    "    x_local, y_local, z_local, rgb_local = [], [], [], []\n",
    "\n",
    "    # Convert depth to float32 for accurate calculations\n",
    "    depth_array = depth_array.astype(np.float32)\n",
    "\n",
    "    for i in range(depth_array.shape[0]):\n",
    "        for j in range(depth_array.shape[1]):\n",
    "            # if random.random() < SAMPLE_RATIO:\n",
    "            if True:\n",
    "                x, y, z = convert_from_uvd(j, i, depth_array[i, j], intrinsic_matrix, pose)\n",
    "                if x is None:\n",
    "                    continue\n",
    "        \n",
    "                x_local.append(x)\n",
    "                y_local.append(y)\n",
    "                z_local.append(z)\n",
    "\n",
    "                ci = int(i * color_array.shape[0] / depth_array.shape[0])\n",
    "                cj = int(j * color_array.shape[1] / depth_array.shape[1])\n",
    "                rgb_local.append(color_array[ci, cj] / 255.0)\n",
    "\n",
    "    # Add the points to the local point cloud        \n",
    "    point_cloud_local = np.vstack((x_local, y_local, z_local)).T\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud_local)\n",
    "    pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "    # Add color to the point cloud\n",
    "    # pcd.colors = o3d.utility.Vector3dVector(rgb_local)\n",
    "    point_cloud += pcd\n",
    "\n",
    "    # Clear memory\n",
    "    depth_image = None\n",
    "    color_image = None\n",
    "    depth_array = None\n",
    "    color_array = None\n",
    "    pcd = None\n",
    "\n",
    "# Create an Open3D mesh representing coordinate axes\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1, origin=[0, 0, 0])\n",
    "\n",
    "# Visualize the final point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud, axes])\n",
    "\n",
    "point_cloud_global = None\n",
    "pcd = None\n",
    "point_cloud = None\n",
    "axes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0000\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\SyntheticV2\\gt_depth\\gt-rgb-depth-0000.png\n",
      "Pose: [[-1.          0.00000004 -0.00000008  0.5       ]\n",
      " [-0.          0.866025    0.5         1.        ]\n",
      " [ 0.00000009  0.5        -0.866025    2.3       ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:01,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0010\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\SyntheticV2\\gt_depth\\gt-rgb-depth-0010.png\n",
      "Pose: [[-0.999848    0.00000004 -0.0174525   0.496667  ]\n",
      " [-0.0087262   0.866025    0.499924    0.983333  ]\n",
      " [ 0.0151143   0.5        -0.865893    2.32887   ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0020\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\SyntheticV2\\gt_depth\\gt-rgb-depth-0020.png\n",
      "Pose: [[-0.999391    0.00000004 -0.0348996   0.493333  ]\n",
      " [-0.0174497   0.866025    0.499695    0.966667  ]\n",
      " [ 0.0302239   0.5        -0.865498    2.35773   ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:00<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0030\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\SyntheticV2\\gt_depth\\gt-rgb-depth-0030.png\n",
      "Pose: [[-0.998629    0.00000004 -0.052336    0.49      ]\n",
      " [-0.026168    0.866025    0.499315    0.95      ]\n",
      " [ 0.0453244   0.5        -0.864838    2.3866    ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0040\n",
      "G:\\Universitat Siegen\\SA\\P-GPU\\Code\\gaussian-splatting\\data\\RGBD_Data\\SyntheticV2\\gt_depth\\gt-rgb-depth-0040.png\n",
      "Pose: [[-0.997564    0.00000004 -0.0697565   0.486667  ]\n",
      " [-0.0348782   0.866025    0.498782    0.933333  ]\n",
      " [ 0.060411    0.5        -0.863916    2.41547   ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Resized Implementations\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "\n",
    "# Using Numpy to create point clouds\n",
    "for i in tqdm(range(start_index, len(depth_files),frame_step)):\n",
    "# for i in range(start_index, len(files),frame_step):\n",
    "# for i in tqdm(range(1)):\n",
    "    depth_file_name = depth_files[i]\n",
    "    depth_file = os.path.join(depth_directory, depth_file_name)\n",
    "    \n",
    "    # Get the corresponding color image\n",
    "    color_file = os.path.join(rgb_directory, \"rgb-\" + depth_file_name[-8:])  # Assuming both files have corresponding indices\n",
    "    \n",
    "    frame_id = depth_file_name.split('-')[3].split('.')[0]\n",
    "\n",
    "    # Read the depth and color images\n",
    "    depth_image = cv2.imread(depth_file, cv2.IMREAD_UNCHANGED)\n",
    "    depth_image = cv2.resize(depth_image, (512, 424), interpolation=cv2.INTER_NEAREST)\n",
    "    color_image = cv2.imread(color_file, cv2.IMREAD_UNCHANGED)\n",
    "    color_image = cv2.resize(color_image, (512, 424), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Convert images to numpy arrays\n",
    "    depth_array = np.asarray(depth_image)\n",
    "\n",
    "    color_array = np.asarray(color_image)\n",
    "    color_array = color_array[:, :, :3]\n",
    "\n",
    "    # print(np.shape(color_array), np.shape(depth_array))\n",
    "\n",
    "    # print(np.min(depth_array), np.max(depth_array))\n",
    "    # print(np.min(color_array), np.max(color_array))\n",
    "\n",
    "    width = depth_array.shape[1]\n",
    "    height = depth_array.shape[0]\n",
    "\n",
    "    # Intrinsic parameters of the camera (you may need to adjust these values)\n",
    "    cx = depth_camera_params['cx,cy,fx,fy'][0]\n",
    "    cy = depth_camera_params['cx,cy,fx,fy'][1]\n",
    "    fx = depth_camera_params['cx,cy,fx,fy'][2] \n",
    "    fy = depth_camera_params['cx,cy,fx,fy'][3]\n",
    "\n",
    "    # vFov = rgb_camera_params['vFov']\n",
    "    # hFov = rgb_camera_params['hFov']\n",
    "    # print(\"vFov:\", vFov)\n",
    "    # print(\"hFov:\", hFov)\n",
    "    # x_corr = math.tan(math.radians(hFov/2)) / (1920/2)\n",
    "    # y_corr = math.tan(math.radians(vFov/2)) / (1080/2)\n",
    "\n",
    "    print(\"Frame:\", frame_id)\n",
    "    assert frame_id in extrinsics, \"No pose found for frame \" + frame_id\n",
    "\n",
    "    pose = extrinsics[frame_id]\n",
    "    # pose = np.linalg.inv(pose)\n",
    "\n",
    "    print(depth_file)\n",
    "    print(\"Pose:\", pose)\n",
    "\n",
    "    # Convert depth to 3D coordinates in camera coordinates\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    u = u.flatten()\n",
    "    v = v.flatten()\n",
    "\n",
    "    # Convert depth to float32 for accurate calculations\n",
    "    depth_image = depth_image.astype(np.float32)\n",
    "    depth_scale = 1000.0\n",
    "    depth = depth_image.flatten() / depth_scale\n",
    "    X = ((u - cx) * depth / fx)\n",
    "    Y = ((v - cy) * depth / fy) \n",
    "    Z = depth\n",
    "\n",
    "    # print(np.min(depth), np.max(depth))\n",
    "\n",
    "    rgb_values = color_array.reshape((-1, 3)) / 255.0\n",
    "    \n",
    "    # Stack the 3D coordinates\n",
    "    points_camera = np.vstack((X, Y, Z, np.ones_like(X)))\n",
    "\n",
    "    if False:\n",
    "        # Extract the transformed X, Y, Z coordinates\n",
    "        X_local = points_camera[0, :]\n",
    "        Y_local = points_camera[1, :]\n",
    "        Z_local = points_camera[2, :]\n",
    "        # Stack the global coordinates\n",
    "        point_cloud_local = np.vstack((X_local, Y_local, Z_local)).T\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(point_cloud_local)\n",
    "        pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "        # Add color to the point cloud\n",
    "        pcd.colors = o3d.utility.Vector3dVector(rgb_values)\n",
    "        point_cloud += pcd\n",
    "\n",
    "    # print(\"Frame:\", frame_id)\n",
    "    # print(\"Pose:\", pose)\n",
    "    # Transform to global coordinates\n",
    "    # updated_pose_matrix = np.dot(pose, tof_extrinsic_matrix)\n",
    "    points_global = np.dot(pose, points_camera)\n",
    "\n",
    "    # Extract the transformed X, Y, Z coordinates\n",
    "    X_global = points_global[0, :] / points_global[3 , :]\n",
    "    Y_global = points_global[1, :] / points_global[3 , :]\n",
    "    Z_global = points_global[2, :] / points_global[3 , :]\n",
    "    # Stack the global coordinates\n",
    "    point_cloud_global = np.vstack((X_global, Y_global, Z_global)).T\n",
    "\n",
    "    # Create an Open3D PointCloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    # Set the points in the PointCloud\n",
    "    pcd.points = o3d.utility.Vector3dVector(point_cloud_global)\n",
    "\n",
    "    # Flip the point cloud\n",
    "    pcd.transform([[1, 0, 0, 0],[0, -1, 0, 0],[0, 0, -1, 0],[0, 0, 0, 1]])\n",
    "\n",
    "    # Add color to the point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(rgb_values)\n",
    "    \n",
    "    # Save the point cloud to a file\n",
    "    # ply_file_path = os.path.join(ply_path, frame_id + \".ply\")    \n",
    "    # o3d.io.write_point_cloud(ply_file_path, pcd)\n",
    "\n",
    "    # Merge current point cloud with the overall point cloud\n",
    "    point_cloud += pcd\n",
    "\n",
    "    # Clear memory\n",
    "    depth_image = None\n",
    "    color_image = None\n",
    "    depth_array = None\n",
    "    color_array = None\n",
    "    pcd = None\n",
    "\n",
    "\n",
    "# Create an Open3D mesh representing coordinate axes\n",
    "axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1, origin=[0, 0, 0])\n",
    "\n",
    "# Visualize the final point cloud\n",
    "o3d.visualization.draw_geometries([point_cloud, axes])\n",
    "\n",
    "pcd = None\n",
    "point_cloud = None\n",
    "axes = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
